technical_replicates = data.frame("Batch1" = c("Old_trimmed_2", "Old_trimmed_86",
"Old_trimmed_85", "Old_trimmed_49",
"Old_trimmed_38", "Old_trimmed_3",
"Old_trimmed_13", "Old_trimmed_26"),
"Batch2" = c("New_trimmed_29", "New_trimmed_35",
"New_trimmed_41", "New_trimmed_47",
"New_trimmed_53", "New_trimmed_59",
"New_trimmed_65", "New_trimmed_71"))
# wrap dataframe for technical replicates in each batch ordered by match (line ~336 original_pipeline2.R)
count_replicate = list()
PA_replicate = list()
counts = dat
for (i in 1:dplyr::n_distinct(meta$batch)) {
vals = technical_replicates[,i]
count_replicate[[i]] = data.frame(t(counts[vals,]))
# create presence absence matrices
j = as.matrix(count_replicate[[i]])
j[j!=0] = 1
PA_replicate[[i]] = j
}
# create dataframe to contain results from IRR kappa
kappa_results = data.frame(value = numeric(), statistic = numeric(), p.value = numeric())
# get kappa values using for loop
batch1.df.PA = PA_replicate[[1]]
batch2.df.PA = PA_replicate[[2]]
View(batch1.df.PA)
for (i in nrow(PA_replicate[[1]])) {
k = kappa2(t(rbind(batch1.df.PA[i,], batch2.df.PA[i,])), "unweighted")
kappa_results[i,"value"] = k$value
kappa_results[i,"statistic"] = k$statistic
kappa_results[i,"p.value"] = k$p.value
}
library(phyloseq) # object wrapper
library(SummarizedExperiment) # object wrapper
library(tidyverse)
library(plotly) # for interactive feature
library(SCRuB) # pipeline 1
library(decontam) # pipeline 2 step2
library(microDecon) # pipeline 2
library(ANCOMBC) # pipeline 2
library(ggVennDiagram) # function 3 - pipeline 2 - comparison across removed
library(shiny) # function 3
library(ANCOMBC) # pipeline 2 step1
library(irr) # pipeline 2 step3
for (i in nrow(PA_replicate[[1]])) {
k = kappa2(t(rbind(batch1.df.PA[i,], batch2.df.PA[i,])), "unweighted")
kappa_results[i,"value"] = k$value
kappa_results[i,"statistic"] = k$statistic
kappa_results[i,"p.value"] = k$p.value
}
View(kappa_results)
for (i in nrow(PA_replicate[[1]])) {
k = kappa2(t(rbind(batch1.df.PA[i,], batch2.df.PA[i,])), "unweighted")
kappa_results[i,"value"] = k$value
kappa_results[i,"statistic"] = k$statistic
kappa_results[i,"p.value"] = k$p.value
}
row.names(kappa_results) = colnames(counts)
kappa_results.no_NA = subset(kappa_results, !is.na(value) & !is.na(p.value))
View(kappa_results.no_NA)
step1 = function(counts, meta) {
phyloseq = wrap_phyloseq(counts, meta)
# run differential analysis
s1 = ancombc(phyloseq = phyloseq, assay_name = "counts",
group = "batch", p_adj_method = "BH", lib_cut = 0,
formula = "batch",
struc_zero = TRUE, neg_lb = FALSE,
tol = 1e-5, max_iter = 100, conserve = FALSE,
alpha = 0.05, global = TRUE)
# create results matrix
s1_res = do.call(cbind, s1$res)
# identify column for diff results
col = ncol(s1_res)
# return indices for which differentially abundant across batches
ind = which(s1_res[,col]==TRUE)
# return list of tagged contaminant features
return(s1_res[ind,1])
}
step2 = function(counts, meta, threshold) {
# subset to only batches that contain negative controls
# create phyloseq object
phyloseq =  wrap_phyloseq(counts, meta)
# run decontam prevalence method
s2_res = isContaminant(phyloseq, method="prevalence", neg="is_control", threshold=threshold)
# return indices for which features identified as contaminant by decontam prevalence method
ind = which(s2_res$contaminant)
# return list of tagged contaminant features
return(rownames(s2_res[ind,]))
}
step3 = function(counts, technical_replicates) {
# wrap dataframe for technical replicates in each batch ordered by match (line ~336 original_pipeline2.R)
count_replicate = list()
PA_replicate = list()
for (i in 1:dplyr::n_distinct(meta$batch)) {
vals = technical_replicates[,i]
count_replicate[[i]] = data.frame(t(counts[vals,]))
# create presence absence matrices
j = as.matrix(count_replicate[[i]])
j[j!=0] = 1
PA_replicate[[i]] = j
}
# create dataframe to contain results from IRR kappa
kappa_results = data.frame(value = numeric(), statistic = numeric(), p.value = numeric())
# get kappa values using for loop
batch1.df.PA = PA_replicate[[1]]
batch2.df.PA = PA_replicate[[2]]
for (i in nrow(PA_replicate[[1]])) {
k = kappa2(t(rbind(batch1.df.PA[i,], batch2.df.PA[i,])), "unweighted")
kappa_results[i,"value"] = k$value
kappa_results[i,"statistic"] = k$statistic
kappa_results[i,"p.value"] = k$p.value
}
row.names(kappa_results) = colnames(counts)
kappa_results.no_NA = subset(kappa_results, !is.na(value) & !is.na(p.value))
kappa_res_remove = subset(kappa_results.no_NA, p.value >= 0.05 | value <= 0.4)
return(rownames(kappa_res_remove))
}
step4 = function(counts, meta, blocklist) {
allTaxa = colnames(counts)
return(allTaxa[(allTaxa %in% blocklist)])
}
pipeline2 = function(counts, meta, blocklist, remove_if = 1, step2_threshold = 0.5,
technical_replicates, seed = 42) {
set.seed(seed)
# Step 0: W2W check
w2w = well2well(counts, meta, seed = seed)
# Step 1: Remove features that showed different abundance in different batches
## ancombc comparison across batches
s1_res = step1(counts, meta)
# Step 2: Remove features that are differentially abundant in negative controls
## decontam
s2_res = step2(counts, meta, step2_threshold)
# Step 3: Remove if DA in diff batches for technical replicates
s3_res = step3(counts, meta, technical_replicates)
# Step 4: Remove known 'blocklist' of contaminants
s4_res = step4(counts, meta, blocklist)
# Create dataframe indicating TRUE if contaminant and FALSE if not tagged
res = data.frame('feature' = colnames(counts))
res = data.frame('step1' = ifelse(colnames(counts) %in% s1_res, TRUE, FALSE),
'step2' = ifelse(colnames(counts) %in% s2_res, TRUE, FALSE),
'step3' = ifelse(colnames(counts) %in% s3_res, TRUE, FALSE),
'step4' = ifelse(colnames(counts) %in% s4_res, TRUE, FALSE))
rownames(res) = colnames(counts)
# return column with summed cases where feature was true
# transpose to same as counts matrix
res2 = res
res2$remove = rowSums(res2)
res2 = t(res)
# remove features above specified threshold from original counts frame
counts = rbind(counts, res2['remove',])
rownames(counts)[nrow(counts)] = 'remove'
final_counts = counts[counts['remove'<remove_if,]==TRUE,]
removed = counts[counts['remove'>remove_if,]==TRUE,]
# determine filtering loss value
FL = FL(counts, removed)
# Create deliverable
deliv = list('contaminant_id' = res,
'decontaminated_count' = final_counts,
'filtering_loss' = FL)
return(deliv)
}
# Import blocklist (Eisenhofer et al., 2019) and genus data
blocklist = read.csv("../Data/contaminant-blocklist.csv", header = F)
# Import blocklist (Eisenhofer et al., 2019) and genus data
blocklist = read.csv("contaminant-blocklist.csv", header = F)
pipeline2(dat, meta, blocklist, technical_replicates = technical_replicates)
pipeline2 = function(counts, meta, blocklist, remove_if = 1, technical_replicates,
step2_threshold = 0.5, seed = 42) {
set.seed(seed)
# Step 0: W2W check
#  w2w = well2well(counts, meta, seed = seed)
# Step 1: Remove features that showed different abundance in different batches
## ancombc comparison across batches
s1_res = step1(counts, meta)
# Step 2: Remove features that are differentially abundant in negative controls
## decontam
s2_res = step2(counts, meta, step2_threshold)
# Step 3: Remove if DA in diff batches for technical replicates
s3_res = step3(counts, meta, technical_replicates)
# Step 4: Remove known 'blocklist' of contaminants
s4_res = step4(counts, meta, blocklist)
# Create dataframe indicating TRUE if contaminant and FALSE if not tagged
res = data.frame('feature' = colnames(counts))
res = data.frame('step1' = ifelse(colnames(counts) %in% s1_res, TRUE, FALSE),
'step2' = ifelse(colnames(counts) %in% s2_res, TRUE, FALSE),
'step3' = ifelse(colnames(counts) %in% s3_res, TRUE, FALSE),
'step4' = ifelse(colnames(counts) %in% s4_res, TRUE, FALSE))
rownames(res) = colnames(counts)
# return column with summed cases where feature was true
# transpose to same as counts matrix
res2 = res
res2$remove = rowSums(res2)
res2 = t(res)
# remove features above specified threshold from original counts frame
counts = rbind(counts, res2['remove',])
rownames(counts)[nrow(counts)] = 'remove'
final_counts = counts[counts['remove'<remove_if,]==TRUE,]
removed = counts[counts['remove'>remove_if,]==TRUE,]
# determine filtering loss value
FL = FL(counts, removed)
# Create deliverable
deliv = list('contaminant_id' = res,
'decontaminated_count' = final_counts,
'filtering_loss' = FL)
return(deliv)
}
pipeline2(dat, meta, blocklist, technical_replicates = technical_replicates)
wrap_phyloseq = function(counts, meta) {
counts = t(counts) # transpose to fit with expectation of phyloseq object
OTU = otu_table(counts, taxa_are_rows = TRUE)
META = sample_data(meta)
tax_mat = matrix(rownames(counts),nrow=nrow(counts),ncol=1)
rownames(tax_mat) = rownames(counts)
TAX = tax_table(tax_mat)
return(phyloseq(OTU, META, TAX))
}
unwrap_phyloseq = function(phyloseq) {
counts = data.frame(t(phyloseq@otu_table)) # requires data frame first, will not coerce to matrix from phyloseq object
meta = data.frame(phyloseq@sam_data)
return(list(counts = as.matrix(counts), # adjust to matrix for returnable
meta = as.matrix(meta)))
}
pipeline2(dat, meta, blocklist, technical_replicates = technical_replicates)
results = pipeline2(dat, meta, blocklist, technical_replicates = technical_replicates)
results
seed = 42
set.seed(seed)
s1_res = step1(counts, meta)
s2_res = step2(counts, meta, step2_threshold)
step2_threshold = 0.5
s2_res = step2(counts, meta, step2_threshold)
s3_res = step3(counts, meta, technical_replicates)
pipeline2 = function(counts, meta, blocklist, technical_replicates, remove_if = 1,
step2_threshold = 0.5, seed = 42) {
set.seed(seed)
# Step 0: W2W check
w2w = well2well(counts, meta, seed = seed)
# Step 1: Remove features that showed different abundance in different batches
## ancombc comparison across batches
s1_res = step1(counts, meta)
# Step 2: Remove features that are differentially abundant in negative controls
## decontam
s2_res = step2(counts, meta, step2_threshold)
# Step 3: Remove if DA in diff batches for technical replicates
s3_res = step3(counts, technical_replicates)
# Step 4: Remove known 'blocklist' of contaminants
s4_res = step4(counts, meta, blocklist)
# Create dataframe indicating TRUE if contaminant and FALSE if not tagged
res = data.frame('feature' = colnames(counts))
res = data.frame('step1' = ifelse(colnames(counts) %in% s1_res, TRUE, FALSE),
'step2' = ifelse(colnames(counts) %in% s2_res, TRUE, FALSE),
'step3' = ifelse(colnames(counts) %in% s3_res, TRUE, FALSE),
'step4' = ifelse(colnames(counts) %in% s4_res, TRUE, FALSE))
rownames(res) = colnames(counts)
# return column with summed cases where feature was true
# transpose to same as counts matrix
res2 = res
res2$remove = rowSums(res2)
res2 = t(res)
# remove features above specified threshold from original counts frame
counts = rbind(counts, res2['remove',])
rownames(counts)[nrow(counts)] = 'remove'
final_counts = counts[counts['remove'<remove_if,]==TRUE,]
removed = counts[counts['remove'>remove_if,]==TRUE,]
# determine filtering loss value
FL = FL(counts, removed)
# Create deliverable
deliv = list('contaminant_id' = res,
'decontaminated_count' = final_counts,
'filtering_loss' = FL)
return(deliv)
}
results = pipeline2(dat, meta, blocklist, technical_replicates = technical_replicates)
pipeline2 = function(counts, meta, blocklist, technical_replicates, remove_if = 1,
step2_threshold = 0.5, seed = 42) {
set.seed(seed)
# Step 0: W2W check
#  w2w = well2well(counts, meta, seed = seed)
# Step 1: Remove features that showed different abundance in different batches
## ancombc comparison across batches
s1_res = step1(counts, meta)
# Step 2: Remove features that are differentially abundant in negative controls
## decontam
s2_res = step2(counts, meta, step2_threshold)
# Step 3: Remove if DA in diff batches for technical replicates
s3_res = step3(counts, technical_replicates)
# Step 4: Remove known 'blocklist' of contaminants
s4_res = step4(counts, meta, blocklist)
# Create dataframe indicating TRUE if contaminant and FALSE if not tagged
res = data.frame('feature' = colnames(counts))
res = data.frame('step1' = ifelse(colnames(counts) %in% s1_res, TRUE, FALSE),
'step2' = ifelse(colnames(counts) %in% s2_res, TRUE, FALSE),
'step3' = ifelse(colnames(counts) %in% s3_res, TRUE, FALSE),
'step4' = ifelse(colnames(counts) %in% s4_res, TRUE, FALSE))
rownames(res) = colnames(counts)
# return column with summed cases where feature was true
# transpose to same as counts matrix
res2 = res
res2$remove = rowSums(res2)
res2 = t(res)
# remove features above specified threshold from original counts frame
counts = rbind(counts, res2['remove',])
rownames(counts)[nrow(counts)] = 'remove'
final_counts = counts[counts['remove'<remove_if,]==TRUE,]
removed = counts[counts['remove'>remove_if,]==TRUE,]
# determine filtering loss value
FL = FL(counts, removed)
# Create deliverable
deliv = list('contaminant_id' = res,
'decontaminated_count' = final_counts,
'filtering_loss' = FL)
return(deliv)
}
results = pipeline2(dat, meta, blocklist, technical_replicates = technical_replicates)
s1_res = step1(counts, meta)
s2_res = step2(counts, meta, step2_threshold)
s3_res = step3(counts, technical_replicates)
s4_res = step4(counts, meta, blocklist)
View(blocklist)
class(blocklist)
c(blocklist)
class(c(blocklit))
class(c(blocklist))
blocklist = c(blocklist)
allTaxa[(allTaxa %in% blocklist)]
allTaxa = colnames(counts)
allTaxa[(allTaxa %in% blocklist)]
allTaxa %in% blocklist
View(blocklist)
View(counts)
allTaxa
class(allTaxa)
blocklist = as.character(blocklist)
bloclist
blocklist
# Import blocklist (Eisenhofer et al., 2019) and genus data
blocklist = read.csv("contaminant-blocklist.csv", header = F)
blocklist = as.character(blocklist)
allTaxa %in% blocklist
blocklist
# Import blocklist (Eisenhofer et al., 2019) and genus data
blocklist = read.csv("contaminant-blocklist.csv", header = F)
blocklist = as.character(blocklist)
blocklist
# data
blocklist = read.csv("contaminant-blocklist.csv", header = F)
blocklist = as.character(blocklist[,1])
allTaxa[(allTaxa %in% blocklist)]
class(blocklist)
step4 = function(counts, meta, blocklist) {
allTaxa = colnames(counts)
if (class(blocklist)!='character') {
print('The blocklist must be formatted as a character string!')
break
}
return(allTaxa[(allTaxa %in% blocklist)])
}
step4 = function(counts, blocklist) {
allTaxa = colnames(counts)
if (class(blocklist)!='character') {
print('The blocklist must be formatted as a character string!')
break
}
return(allTaxa[(allTaxa %in% blocklist)])
}
step4(dat, blocklist)
pipeline2 = function(counts, meta, blocklist, technical_replicates, remove_if = 1,
step2_threshold = 0.5, seed = 42) {
set.seed(seed)
# Step 0: W2W check
w2w = well2well(counts, meta, seed = seed)
# Step 1: Remove features that showed different abundance in different batches
## ancombc comparison across batches
s1_res = step1(counts, meta)
# Step 2: Remove features that are differentially abundant in negative controls
## decontam
s2_res = step2(counts, meta, step2_threshold)
# Step 3: Remove if DA in diff batches for technical replicates
s3_res = step3(counts, technical_replicates)
# Step 4: Remove known 'blocklist' of contaminants
s4_res = step4(counts, blocklist)
# Create dataframe indicating TRUE if contaminant and FALSE if not tagged
res = data.frame('feature' = colnames(counts))
res = data.frame('step1' = ifelse(colnames(counts) %in% s1_res, TRUE, FALSE),
'step2' = ifelse(colnames(counts) %in% s2_res, TRUE, FALSE),
'step3' = ifelse(colnames(counts) %in% s3_res, TRUE, FALSE),
'step4' = ifelse(colnames(counts) %in% s4_res, TRUE, FALSE))
rownames(res) = colnames(counts)
# return column with summed cases where feature was true
# transpose to same as counts matrix
res2 = res
res2$remove = rowSums(res2)
res2 = t(res)
# remove features above specified threshold from original counts frame
counts = rbind(counts, res2['remove',])
rownames(counts)[nrow(counts)] = 'remove'
final_counts = counts[counts['remove'<remove_if,]==TRUE,]
removed = counts[counts['remove'>remove_if,]==TRUE,]
# determine filtering loss value
FL = FL(counts, removed)
# Create deliverable
deliv = list('contaminant_id' = res,
'decontaminated_count' = final_counts,
'filtering_loss' = FL)
return(deliv)
}
results = pipline(dat, meta, blocklist)
results = pipline2(dat, meta, blocklist)
results = pipeline2(dat, meta, blocklist)
pipeline2 = function(counts, meta, blocklist, technical_replicates, remove_if = 1,
step2_threshold = 0.5, seed = 42) {
set.seed(seed)
# Step 0: W2W check
#  w2w = well2well(counts, meta, seed = seed)
# Step 1: Remove features that showed different abundance in different batches
## ancombc comparison across batches
s1_res = step1(counts, meta)
# Step 2: Remove features that are differentially abundant in negative controls
## decontam
s2_res = step2(counts, meta, step2_threshold)
# Step 3: Remove if DA in diff batches for technical replicates
s3_res = step3(counts, technical_replicates)
# Step 4: Remove known 'blocklist' of contaminants
s4_res = step4(counts, blocklist)
# Create dataframe indicating TRUE if contaminant and FALSE if not tagged
res = data.frame('feature' = colnames(counts))
res = data.frame('step1' = ifelse(colnames(counts) %in% s1_res, TRUE, FALSE),
'step2' = ifelse(colnames(counts) %in% s2_res, TRUE, FALSE),
'step3' = ifelse(colnames(counts) %in% s3_res, TRUE, FALSE),
'step4' = ifelse(colnames(counts) %in% s4_res, TRUE, FALSE))
rownames(res) = colnames(counts)
# return column with summed cases where feature was true
# transpose to same as counts matrix
res2 = res
res2$remove = rowSums(res2)
res2 = t(res)
# remove features above specified threshold from original counts frame
counts = rbind(counts, res2['remove',])
rownames(counts)[nrow(counts)] = 'remove'
final_counts = counts[counts['remove'<remove_if,]==TRUE,]
removed = counts[counts['remove'>remove_if,]==TRUE,]
# determine filtering loss value
FL = FL(counts, removed)
# Create deliverable
deliv = list('contaminant_id' = res,
'decontaminated_count' = final_counts,
'filtering_loss' = FL)
return(deliv)
}
results = pipeline2(dat, meta, blocklist)
s4_res = step4(counts, blocklist)
# Create dataframe indicating TRUE if contaminant and FALSE if not tagged
res = data.frame('feature' = colnames(counts))
res = data.frame('step1' = ifelse(colnames(counts) %in% s1_res, TRUE, FALSE),
'step2' = ifelse(colnames(counts) %in% s2_res, TRUE, FALSE),
'step3' = ifelse(colnames(counts) %in% s3_res, TRUE, FALSE),
'step4' = ifelse(colnames(counts) %in% s4_res, TRUE, FALSE))
View(res)
rownames(res) = colnames(counts)
# transpose to same as counts matrix
res2 = res
res2$remove = rowSums(res2)
res2 = t(res)
View(res2)
# remove features above specified threshold from original counts frame
counts = rbind(counts, res2['remove',])
# remove features above specified threshold from original counts frame
counts = rbind(counts, res2[,'remove'])
# transpose to same as counts matrix
res2 = res
res2$remove = rowSums(res2)
res2 = t(res)
# transpose to same as counts matrix
res2 = res
res2$remove = rowSums(res2)
res2 = t(res2)
# remove features above specified threshold from original counts frame
counts = rbind(counts, res2[,'remove'])
# remove features above specified threshold from original counts frame
counts = rbind(counts, res2['remove',])
rownames(counts)[nrow(counts)] = 'remove'
final_counts = counts[counts['remove'<remove_if,]==TRUE,]
remove_if = 1
final_counts = counts[counts['remove'<remove_if,]==TRUE,]
removed = counts[counts['remove'>remove_if,]==TRUE,]
counts['remove'>remove_if,]
View(dat)
removed = setdiff(colnames(final_counts), colnames(counts))
counts[counts['remove'<remove_if,]==TRUE,]
counts['remove'<remove_if,]==TRUE
counts['remove'<remove_if,]
counts$remove
counts
View(counts)
counts[,'remove']
class(counts)
rbind(counts, res2['remove',])
# remove features above specified threshold from original counts frame
counts_rem = rbind(counts, res2['remove',])
res2['remove',]
View(res2[,'remove'])
View(res2['remove',])
class(res2[])
class(res2['remove',])
View(counts)
View(res2)
setdiff(colnames(res2), colnames(counts))
counts['remove',]
counts[counts['remove'<remove_if,]==TRUE,]
counts['remove'<remove_if,]==TRUE
final_counts = counts[counts['remove'<remove_if,]==TRUE,]
counts['remove'<remove_if,]
