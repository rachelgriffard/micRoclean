### dummy data for development
dat = read.csv("Level6_Genus.csv", header=T,row.name=1)
setwd("~/GitHub/micRoclean_development")
### dummy data for development
dat = read.csv("Level6_Genus.csv", header=T,row.name=1)
batch = dat$Batch
group = dat$Groups
index = grep(".*.g__*", colnames(dat)) # keep if have IDed datus
dat = dat[,index]
comp = data.frame(colnames(dat))
comp$compare = sub(".*.g__", "", colnames(dat)) # subset to only datus
index2 = which(comp$compare=="")
comp = comp[-index2,]
index = grep(".*.g__*", colnames(dat)) # keep if have IDed datus
dat = dat[,index]
colnames(dat) = sub(".*.g__", "", colnames(dat)) # subset to only datus
index2 = which(names(dat)=="")
dat = dat[,-index2] # remove if no value
control = group
control = control == "Negative Control"
sample = group
sample[!sample == "Control"] = "Plasma"
dat = as.matrix(dat)
meta = data.frame("is_control" = control,
"sample" = sample,
"batch" = batch)
rownames(meta) = rownames(dat)
### dummy technical replicates (p2s3)
technical_replicates = data.frame("Batch1" = c("Old_trimmed_2", "Old_trimmed_86",
"Old_trimmed_85", "Old_trimmed_49",
"Old_trimmed_38", "Old_trimmed_3",
"Old_trimmed_13", "Old_trimmed_26"),
"Batch2" = c("New_trimmed_29", "New_trimmed_35",
"New_trimmed_41", "New_trimmed_47",
"New_trimmed_53", "New_trimmed_59",
"New_trimmed_65", "New_trimmed_71"))
counts = dat
Function 2A: Step 1 Pipeline 2
step1 = function(counts, meta) {
phyloseq = wrap_phyloseq(counts, meta)
# run differential analysis
s1 = ancombc(phyloseq = phyloseq, assay_name = "counts",
group = "batch", p_adj_method = "BH", lib_cut = 0,
formula = "batch",
struc_zero = TRUE, neg_lb = FALSE,
tol = 1e-5, max_iter = 100, conserve = FALSE,
alpha = 0.05, global = TRUE)
# create results matrix
s1_res = do.call(cbind, s1$res)
# identify column for diff results
col = ncol(s1_res)
# return indices for which differentially abundant across batches
ind = which(s1_res[,col]==TRUE)
# return list of tagged contaminant features
return(s1_res[ind,1])
}
step2 = function(counts, meta, threshold) {
# subset to only batches that contain negative controls
# create phyloseq object
phyloseq =  wrap_phyloseq(counts, meta)
# run decontam prevalence method
s2_res = isContaminant(phyloseq, method="prevalence", neg="is_control", threshold=threshold)
# return indices for which features identified as contaminant by decontam prevalence method
ind = which(s2_res$contaminant)
# return list of tagged contaminant features
return(rownames(s2_res[ind,]))
}
step3 = function(counts, technical_replicates) {
# wrap dataframe for technical replicates in each batch ordered by match (line ~336 original_pipeline2.R)
count_replicate = list()
PA_replicate = list()
for (i in 1:dplyr::n_distinct(meta$batch)) {
vals = technical_replicates[,i]
count_replicate[[i]] = data.frame(t(counts[vals,]))
# create presence absence matrices
j = as.matrix(count_replicate[[i]])
j[j!=0] = 1
PA_replicate[[i]] = j
}
# create dataframe to contain results from IRR kappa
kappa_results = data.frame(value = numeric(), statistic = numeric(), p.value = numeric())
# get kappa values using for loop
batch1.df.PA = PA_replicate[[1]]
batch2.df.PA = PA_replicate[[2]]
for (i in nrow(PA_replicate[[1]])) {
k = kappa2(t(rbind(batch1.df.PA[i,], batch2.df.PA[i,])), "unweighted")
kappa_results[i,"value"] = k$value
kappa_results[i,"statistic"] = k$statistic
kappa_results[i,"p.value"] = k$p.value
}
row.names(kappa_results) = colnames(counts)
kappa_results.no_NA = subset(kappa_results, !is.na(value) & !is.na(p.value))
kappa_res_remove = subset(kappa_results.no_NA, p.value >= 0.05 | value <= 0.4)
return(rownames(kappa_res_remove))
}
step4 = function(counts, blocklist) {
allTaxa = colnames(counts)
if (class(blocklist)!='character') {
print('The blocklist must be formatted as a character string!')
break
}
return(allTaxa[(allTaxa %in% blocklist)])
}
wrap_phyloseq = function(counts, meta) {
counts = t(counts) # transpose to fit with expectation of phyloseq object
OTU = otu_table(counts, taxa_are_rows = TRUE)
META = sample_data(meta)
tax_mat = matrix(rownames(counts),nrow=nrow(counts),ncol=1)
rownames(tax_mat) = rownames(counts)
TAX = tax_table(tax_mat)
return(phyloseq(OTU, META, TAX))
}
s1_res = step1(counts, meta)
# Required libraries
library(phyloseq) # object wrapper
library(SummarizedExperiment) # object wrapper
library(tidyverse)
library(plotly) # for interactive feature
library(SCRuB) # pipeline 1
library(decontam) # pipeline 2 step2
library(microDecon) # pipeline 2
library(ANCOMBC) # pipeline 2
library(ggVennDiagram) # function 3 - pipeline 2 - comparison across removed
library(shiny) # function 3
library(ANCOMBC) # pipeline 2 step1
library(irr) # pipeline 2 step3
set.seed(seed)
s1_res = step1(counts, meta)
s2_res = step2(counts, meta, step2_threshold)
step2_threshold = 0.5
s2_res = step2(counts, meta, step2_threshold)
# Import blocklist (Eisenhofer et al., 2019) and genus data
blocklist = read.csv("contaminant-blocklist.csv", header = F)
s3_res = step3(counts, technical_replicates)
s4_res = step4(counts, blocklist)
blocklist = as.character(blocklist[,1])
blocklist
s4_res = step4(counts, blocklist)
# Create dataframe indicating TRUE if contaminant and FALSE if not tagged
res = data.frame('feature' = colnames(counts))
View(res)
colnames(counts) %in% s1_res
'step1' = ifelse(colnames(counts) %in% s1_res, TRUE, FALSE)
res = data.frame('step1' = ifelse(colnames(counts) %in% s1_res, TRUE, FALSE),
'step2' = ifelse(colnames(counts) %in% s2_res, TRUE, FALSE),
'step3' = ifelse(colnames(counts) %in% s3_res, TRUE, FALSE),
'step4' = ifelse(colnames(counts) %in% s4_res, TRUE, FALSE))
rownames(res) = colnames(counts)
View(res)
# transpose to same as counts matrix
res2 = res
res2$remove = rowSums(res2)
res2 = t(res2)
View(res2)
# remove features above specified threshold from original counts frame
counts_rem = rbind(counts, res2['remove',])
rownames(counts)[nrow(counts)]
rownames(counts_rem)[nrow(counts_rem)] = 'remove'
rownames(counts_rem)[nrow(counts_rem)]
# remove features above specified threshold from original counts frame
counts_rem = rbind(counts, res2['remove',])
rownames(counts_rem)[nrow(counts_rem)]
rownames(counts_rem)[nrow(counts_rem)] = 'remove'
counts_rem['remove'<remove_if,]==TRUE
remove_if = 1
counts_rem['remove'<remove_if,]==TRUE
counts[counts_rem['remove'<remove_if,]==TRUE,]
counts[counts_rem['remove'<remove_if,],]
final_counts = counts[counts_rem['remove'<remove_if,],]
View(final_counts)
final_counts = counts[,counts_rem['remove'<remove_if,]]
index = counts_rem['remove'<remove_if,]
View(index)
index = counts_rem['remove'<remove_if==TRUE,]
View(index)
