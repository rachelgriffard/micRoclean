sc_outs_vert[batch] == SCRuB(counts[index,],
meta_vert[index,] %>%
select(is_control, sample_type, sample_well))
}
index = meta_vert %>% filter(dat$batch == b) %>% row.names()
index = meta_vert %>% filter(meta$batch == b) %>% row.names()
# create SCRuB objects by batch
sc_outs_vert = list()
for(b in unique(meta_vert$batch)) {
index = meta_vert %>% filter(batch == b) %>% row.names()
sc_outs_vert[batch] == SCRuB(counts[index,],
meta_vert[index,] %>%
select(is_control, sample_type, sample_well))
}
# create SCRuB objects by batch
sc_outs_vert = list()
for(b in unique(meta_vert$batch)) {
index = meta_vert %>% filter(batch == b) %>% row.names()
sc_outs_vert[batch] = SCRuB(counts[index,],
meta_vert[index,] %>%
select(is_control, sample_type, sample_well))
}
for(b in unique(meta_vert$batch)) {
index = meta_vert %>% filter(batch == b) %>% row.names()
sc_outs_vert[[batch]] = SCRuB(counts[index,],
meta_vert[index,] %>%
select(is_control, sample_type, sample_well))
}
View(sc_outs_vert)
unique(meta_vert$batch)
b = "New"
index = meta_vert %>% filter(batch == b) %>% row.names()
sc_outs_vert[[batch]] = SCRuB(counts[index,],
meta_vert[index,] %>%
select(is_control, sample_type, sample_well))
View(sc_outs_vert)
# create SCRuB objects by batch
sc_outs_vert = list()
for(b in unique(meta_vert$batch)) {
index = meta_vert %>% filter(batch == b) %>% row.names()
sc_outs_vert[[b]] = SCRuB(counts[index,],
meta_vert[index,] %>%
select(is_control, sample_type, sample_well))
}
View(sc_outs_vert)
sc_outs_vert[[b]] = SCRuB(counts[index,],
meta_vert[index,] %>%
select(is_control, sample_type, sample_well))[1]
sc_outs_vert[[b]] = SCRuB(counts[index,],
meta_vert[index,] %>%
select(is_control, sample_type, sample_well))
# create SCRuB objects by batch
sc_outs_vert = list()
for(b in unique(meta_vert$batch)) {
index = meta_vert %>% filter(batch == b) %>% row.names()
sc_outs_vert[[b]] = SCRuB(counts[index,],
meta_vert[index,] %>%
select(is_control, sample_type, sample_well))
}
View(sc_outs_vert)
sum(is.na(dat))
View(counts)
# create SCRuB objects by batch
sc_outs_vert = list()
for(b in unique(meta_vert$batch)) {
index = meta_vert %>% filter(batch == b) %>% row.names()
sc_outs_vert[[b]] = SCRuB(counts[index,],
meta_vert[index,] %>%
select(is_control, sample_type, sample_well))
}
unique(meta_vert$batch)
b = "Old"
index = meta_vert %>% filter(batch == b) %>% row.names()
sc_outs_vert[[b]] = SCRuB(counts[index,],
meta_vert[index,] %>%
select(is_control, sample_type, sample_well))
meta_vert[index,] %>%
select(is_control, sample_type, sample_well)
is.na(counts[index,])
sum(is.na(counts[index,]))
sum(!is.numeric(counts[index,]))
SCRuB(counts[index,],
meta_vert[index,] %>%
select(is_control, sample_type, sample_well))
sapply(counts[index,], class)
sum(sapply(counts[index,], class)!="numeric")
sc_outs_vert[[b]]
sc_outs_horiz = list()
for(b in unique(meta_horiz$batch)) {
index = meta_horiz %>% filter(batch == b) %>% row.names()
sc_outs_vert[[b]] = SCRuB(counts[index,],
meta_horiz[index,] %>%
select(is_control, sample_type, sample_well))
}
View(sc_outs_horiz)
index = meta_horiz %>% filter(batch == b) %>% row.names()
sc_outs_vert[[b]] = SCRuB(counts[index,],
meta_horiz[index,] %>%
select(is_control, sample_type, sample_well))
b = "New"
index = meta_horiz %>% filter(batch == b) %>% row.names()
sc_outs_vert[[b]] = SCRuB(counts[index,],
meta_horiz[index,] %>%
select(is_control, sample_type, sample_well))
head(meta_horiz[index,] %>%
select(is_control, sample_type, sample_well))
sapply(meta_horiz[index,] %>%
select(is_control, sample_type, sample_well), class)
unique(meta_horiz$batch)
sc_outs_horiz = list()
for(b in unique(meta_horiz$batch)) {
index = meta_horiz %>% filter(batch == b) %>% row.names()
sc_outs_vert[[b]] = SCRuB(counts[index,],
meta_horiz[index,] %>%
select(is_control, sample_type, sample_well))
}
View(sc_outs_horiz)
# create SCRuB objects by batch
sc_outs_vert = list()
for(b in unique(meta_vert$batch)) {
index = meta_vert %>% filter(batch == b) %>% row.names()
sc_outs_vert[[b]] = SCRuB(counts[index,],
meta_vert[index,] %>%
select(is_control, sample_type, sample_well))
}
sc_outs_horiz = list()
for(b in unique(meta_horiz$batch)) {
index = meta_horiz %>% filter(batch == b) %>% row.names()
sc_outs_vert[[b]] = SCRuB(counts[index,],
meta_horiz[index,] %>%
select(is_control, sample_type, sample_well))
}
rowSums(dat)
is.na(rowSums(dat))
sum(is.na(rowSums(dat)))
# create SCRuB objects by batch
sc_outs_vert = list()
for(b in unique(meta_vert$batch)) {
index = meta_vert %>% filter(batch == b) %>% row.names()
sc_outs_vert[[b]] = SCRuB(counts[index,],
meta_vert[index,] %>%
select(is_control, sample_type, sample_well))
}
sc_out = list()
for(b in unique(meta$batch)) {
index = meta %>% filter(batch == b) %>% row.names()
sc_outs_vert[[b]] = SCRuB(counts[index,],
meta[index,] %>%
select(is_control, sample_type))
}
sc_out = list()
for(b in unique(meta$batch)) {
index = meta %>% filter(batch == b) %>% row.names()
sc_outs_vert[[b]] = SCRuB(as.matrix(counts[index,]),
meta[index,] %>%
select(is_control, sample_type))
}
View(sc_out)
unique(meta$batch)
b = "New"
index = meta %>% filter(batch == b) %>% row.names()
sc_outs_vert[[b]] = SCRuB(counts[index,],
meta[index,] %>%
select(is_control, sample_type))
sc_outs_horiz = list()
for(b in unique(meta_horiz$batch)) {
index = meta_horiz %>% filter(batch == b) %>% row.names()
sc_outs_horiz[[b]] = SCRuB(counts[index,],
meta_horiz[index,] %>%
select(is_control, sample_type, sample_well))
}
sc_out = list()
for(b in unique(meta$batch)) {
index = meta %>% filter(batch == b) %>% row.names()
sc_outs[[b]] = SCRuB(counts[index,],
meta[index,] %>%
select(is_control, sample_type))
}
sc_outs = list()
for(b in unique(meta$batch)) {
index = meta %>% filter(batch == b) %>% row.names()
sc_outs[[b]] = SCRuB(counts[index,],
meta[index,] %>%
select(is_control, sample_type))
}
View(sc_outs)
remove(sc_out)
index = meta_horiz %>% filter(batch == b) %>% row.names()
temp = SCRuB(counts[index,], meta[index,] %>% select(is_contrl, sample_type))
temp = SCRuB(counts[index,], meta[index,] %>% select(is_control, sample_type))
c_temp = counts[index,]
m_temp = meta[index,]
View(m_temp)
View(c_temp)
sapply(class(c_temp), c)
sapply(c_temp, class)
sum(sapply(c_temp, class)!='numeric')
rowSums(c_temp)
md = meta
df = dat
all_scrub_outputs <- list()
for( scrub_batch in unique(md$batch) ){ # looping through all batches
# specify the row names from a particular batch
batch_indices <- md %>% filter(batch==scrub_batch) %>% row.names()
## run SCRuB, store resultsin the list
all_scrub_outputs[[scrub_batch]] <- SCRuB( df[batch_indices, ],
md[batch_indices, ] %>%
select(is_control, ## I'm making assumptions about the
sample_type, ## metadata's naming structure
sample_well) ## which are probably inacurrate in your case
)
}
all_scrub_outputs <- list()
for( scrub_batch in unique(md$batch) ){ # looping through all batches
# specify the row names from a particular batch
batch_indices <- md %>% filter(batch==scrub_batch) %>% row.names()
## run SCRuB, store resultsin the list
all_scrub_outputs[[scrub_batch]] <- SCRuB( df[batch_indices, ],
md[batch_indices, ] %>%
select(all_of(is_control, ## I'm making assumptions about the
sample_type, ## metadata's naming structure
sample_well)) ## which are probably inacurrate in your case
)
}
meta[index,] %>%
select(is_control, sample_type)
>>>>>>> 062024-pipeline1
library(phyloseq) # object wrapper
library(SummarizedExperiment) # object wrapper
library(tidyverse)
library(plotly) # for interactive feature
library(SCRuB) # well2well, pipeline 1
library(decontam) # pipeline 2 step2
library(microDecon) # pipeline 2
library(ANCOMBC) # pipeline 2
library(ggVennDiagram) # function 3 - pipeline 2 - comparison across removed
library(shiny) # function 3
library(ANCOMBC) # pipeline 2 step1
library(irr) # pip
seed
seed = 42
# basic horiz/vert sort for now
set.seed(seed)
# plate wells
well = data.frame()
for (i in 1:8) { # rows
row = c('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H')
for (j in 1:12) { # columns
well[i,j] = paste0(row[i], j, sep = '')
}
}
# string for well assignments
vert = unname(unlist(well)) # vertical alignment
horiz = unname(unlist(data.frame(t(well)))) # horizontal alignment
# order samples by name convention
meta = meta %>%
arrange(batch, as.numeric(str_extract(rownames(meta), "\\d+$")))
# order batches based on naming convention (number in the end of the string)
meta[order(as.numeric(sub(".*[^0-9](\\d+)$", "\\1", rownames(meta)))),]
# restart at each batch (different plates)
num_b = table(meta$batch)
sample_well = c(vert[1:num_b[1]], vert[1:num_b[2]])
meta_vert = cbind(meta, sample_well)
sample_well = c(horiz[1:num_b[1]], horiz[1:num_b[2]])
meta_horiz = cbind(meta, sample_well)
# order counts by name convention for SCRuB function
counts = as.data.frame(counts) %>%
add_column(meta$batch) %>%
arrange(`meta$batch`, as.numeric(str_extract(rownames(counts), "\\d+$"))) %>%
mutate(`meta$batch` = NULL)
# create SCRuB objects by batch
sc_outs_vert = list()
for(b in unique(meta_vert$batch)) {
index = meta_vert %>% filter(batch == b) %>% row.names()
sc_outs_vert[[b]] = SCRuB(counts[index,],
meta_vert[index,] %>%
select(is_control, sample_type, sample_well))
}
sum(sapply(counts[index,], class)!='numeric')
sapply(meta_vert[index,], class)
technical_replicates = data.frame("Batch1" = c("Old_trimmed_2", "Old_trimmed_86",
"Old_trimmed_85", "Old_trimmed_49",
"Old_trimmed_38", "Old_trimmed_3",
"Old_trimmed_13", "Old_trimmed_26"),
"Batch2" = c("New_trimmed_29", "New_trimmed_35",
"New_trimmed_41", "New_trimmed_47",
"New_trimmed_53", "New_trimmed_59",
"New_trimmed_65", "New_trimmed_71"))
View(technical_replicates)
pipeline2 = function(counts, meta, blocklist, technical_replicates, remove_if = 1,
step2_threshold = 0.5, seed = 42) {
set.seed(seed)
# Step 0: W2W check
#  w2w = well2well(counts, meta, seed = seed)
# Step 1: Remove features that showed different abundance in different batches
## ancombc comparison across batches
s1_res = step1(counts, meta)
# Step 2: Remove features that are differentially abundant in negative controls
## decontam
s2_res = step2(counts, meta, step2_threshold)
# Step 3: Remove if DA in diff batches for technical replicates
s3_res = step3(counts, technical_replicates)
# Step 4: Remove known 'blocklist' of contaminants
s4_res = step4(counts, blocklist)
# Create dataframe indicating TRUE if contaminant and FALSE if not tagged
res = data.frame('feature' = colnames(counts))
res = data.frame('feature' = colnames(counts),
'step1' = ifelse(colnames(counts) %in% s1_res, TRUE, FALSE),
'step2' = ifelse(colnames(counts) %in% s2_res, TRUE, FALSE),
'step3' = ifelse(colnames(counts) %in% s3_res, TRUE, FALSE),
'step4' = ifelse(colnames(counts) %in% s4_res, TRUE, FALSE))
# return column with summed cases where feature was true
# transpose to same as counts matrix
res2 = res
res2$remove = rowSums(res2[,-c(1)])
res2 = t(res2)
# remove features above specified threshold from original counts frame
counts_rem = rbind(counts, res2['remove',])
rownames(counts_rem)[nrow(counts_rem)] = 'remove'
final_counts = counts[,counts_rem['remove',]<remove_if]
removed = setdiff(colnames(counts), colnames(final_counts))
# determine filtering loss value
FL = FL(counts, removed = removed)
# Create deliverable
deliv = list('contaminant_id' = res,
'decontaminated_count' = final_counts,
'removed' = removed,
'filtering_loss' = FL,
'pipeline' = 'pipeline2')
return(deliv)
}
# Function 2A: Step 1 Pipeline 2
#' @name step1
#' @usage Run step 1 of pipeline 2 to identify features that are differentially abundant
#' between batches
#'
#' @param counts Count matrix with samples as rows and features as counts
#' @param meta Matrix with columns is_control, sample_type, and batch
#' @return  Vector of features tagged as contaminants
#' @exportClass vector
step1 = function(counts, meta) {
phyloseq = wrap_phyloseq(counts, meta)
# run differential analysis
suppressWarnings({
s1 = ancombc(phyloseq = phyloseq, assay_name = "counts",
group = "batch", p_adj_method = "BH", lib_cut = 0,
formula = "batch",
struc_zero = TRUE, neg_lb = FALSE,
tol = 1e-5, max_iter = 100, conserve = FALSE,
alpha = 0.05, global = TRUE)
})
# create results matrix
s1_res = do.call(cbind, s1$res)
# identify column for diff results
col = ncol(s1_res)
# return indices for which differentially abundant across batches
ind = which(s1_res[,col]==TRUE)
# return list of tagged contaminant features
return(s1_res[ind,1])
}
# Function 2B: Step 2 Pipeline 2
#' @name step2
#' @usage Run step 2 of pipeline 2 to identify features that are expressed higher in negative
#' controls and lower in samples
#'
#' @param counts Count matrix with samples as rows and features as counts
#' @param meta Matrix with columns is_control, sample_type, and batch
#' @param threshold Threshold value for prevalence method of decontam
#' @return Vector of features tagged as contaminants
#' @exportClass vector
step2 = function(counts, meta, threshold) {
# subset to only batches that contain negative controls
# create phyloseq object
phyloseq =  wrap_phyloseq(counts, meta)
# run decontam prevalence method
s2_res = isContaminant(phyloseq, method="prevalence", neg="is_control", threshold=threshold)
# return indices for which features identified as contaminant by decontam prevalence method
ind = which(s2_res$contaminant)
# return list of tagged contaminant features
return(rownames(s2_res[ind,]))
}
# Function 2C: Step 3 Pipeline 2
#' @name step3
#' @usage Run step 3 of pipeline 2 to identify features with different abundance in technical
#' replicates across batches
#'
#' @param counts Count matrix with samples as rows and features as counts
#' @param meta Matrix with columns is_control, sample_type, and batch
#' @param technical_replicates Matrix identifying technical replicates across batches with batch as column and rows matching replicates
#' @return Vector of features tagged as contaminants
#' @exportClass vector
step3 = function(counts, technical_replicates) {
# wrap dataframe for technical replicates in each batch ordered by match (line ~336 original_pipeline2.R)
count_replicate = list()
PA_replicate = list()
for (i in 1:dplyr::n_distinct(meta$batch)) {
vals = technical_replicates[,i]
count_replicate[[i]] = data.frame(t(counts[vals,]))
# create presence absence matrices
j = as.matrix(count_replicate[[i]])
j[j!=0] = 1
PA_replicate[[i]] = j
}
# create dataframe to contain results from IRR kappa
kappa_results = data.frame(value = numeric(), statistic = numeric(), p.value = numeric())
# get kappa values using for loop
batch1.df.PA = PA_replicate[[1]]
batch2.df.PA = PA_replicate[[2]]
for (i in nrow(PA_replicate[[1]])) {
k = kappa2(t(rbind(batch1.df.PA[i,], batch2.df.PA[i,])), "unweighted")
kappa_results[i,"value"] = k$value
kappa_results[i,"statistic"] = k$statistic
kappa_results[i,"p.value"] = k$p.value
}
row.names(kappa_results) = colnames(counts)
kappa_results.no_NA = subset(kappa_results, !is.na(value) & !is.na(p.value))
kappa_res_remove = subset(kappa_results.no_NA, p.value >= 0.05 | value <= 0.4)
return(rownames(kappa_res_remove))
}
# Function 2D: Step 4 Pipeline 2
#' @name step4
#' @usage Run step 4 of pipeline 2 to identify features previously identified as contaminants
#' based on blocklist
#'
#' @param blocklist List of known previously identified contaminant features
#' @param counts Count matrix with samples as rows and features as counts
#' @param meta Matrix with columns is_control, sample_type, and batch
#' @return Vector of features tagged as contaminants
#' @exportClass vector
step4 = function(counts, blocklist) {
allTaxa = colnames(counts)
if (class(blocklist)!='character') {
warning('blocklist parameter must be formatted as a character vector')
break
}
return(allTaxa[(allTaxa %in% blocklist)])
}
# Import blocklist (Eisenhofer et al., 2019) and genus data
blocklist = read.csv("contaminant-blocklist.csv", header = F)
pipeline2(counts, meta)
wrap_phyloseq = function(counts, meta) {
counts = t(counts) # transpose to fit with expectation of phyloseq object
OTU = otu_table(counts, taxa_are_rows = TRUE)
META = sample_data(meta)
tax_mat = matrix(rownames(counts),nrow=nrow(counts),ncol=1)
rownames(tax_mat) = rownames(counts)
TAX = tax_table(tax_mat)
return(phyloseq(OTU, META, TAX))
}
FL = function(counts, new_counts = NULL, removed = NULL){
# for pipeline 1
if (is.null(new_counts) == FALSE) { #pipeline 1
X_R = new_counts
}
# for pipeline 2
if (is.null(removed) == FALSE) {
# Check the format of removed vector
if(class(removed) != "character")
stop('removed argument must be a character vector containing names of taxa to be removed')
Ind = which(colnames(counts) %in%  removed)
X_R = counts[,-Ind]
}
#calculate corresponding norm
Netw = t(as.matrix(counts))%*%as.matrix(counts)
Netw_R = t(as.matrix(X_R))%*%as.matrix(X_R)
FL =  1 - (sum(Netw_R*Netw_R)/sum(Netw*Netw))
return(FL)
}
pipeline2(counts, meta)
pipeline2(counts, meta, blocklist)
pipeline2(counts, meta, blocklist, technical_replicates)
p2 = pipeline2(counts, meta, blocklist, technical_replicates)
blocklist = blocklist[,1]
p2 = pipeline2(counts, meta, blocklist, technical_replicates)
View(p2)
visualize_pipeline = function(pipeline_output, interactive = FALSE)  {
if (pipeline_output$pipeline == 'pipeline1') {
warning('micRoclean does not currently have functionality to visualize SCRuB decontamination')
}
if (pipeline_output$pipeline == 'pipeline2') {
# import data
s1_rem = pipeline_output$contaminant_id$feature[pipeline_output$contaminant_id$step1==TRUE]
s2_rem = pipeline_output$contaminant_id$feature[pipeline_output$contaminant_id$step2==TRUE]
s3_rem = pipeline_output$contaminant_id$feature[pipeline_output$contaminant_id$step3==TRUE]
s4_rem = pipeline_output$contaminant_id$feature[pipeline_output$contaminant_id$step4==TRUE]
# Venn comparison of contaminant taxa removed across steps
x = list(s1_rem, s2_rem, s3_rem, s4_rem)
p = ggVennDiagram(x, stroke.size =1,
category.names = c("Step 1", "Step 2", "Step 3", "Step 4"),
edge_lty = "solid", set_size = 6,
label_alpha = 0.5, label_percent_digit = 1) +
scale_x_continuous(expand = expansion(mult = .2)) +
ggplot2::scale_color_grey(start=0, end=0) +
scale_fill_distiller(direction=1) +
labs(title="Taxa Removal by Step") +
theme(legend.position="none", plot.title=element_text(size=25, hjust = 0.5)) +
scale_fill_distiller(palette = "Spectral")
if (interactive == FALSE) {
return(p)
}
if (interactive == TRUE) {
return(plotly::ggplotly(p))
}
else {
warning('interactive must be set to TRUE or FALSE.')
}
}
else {
warning('Rerun data through pipeline and ensure object in visualize_pipeline is output from pipeline1 or pipeline2.')
}
}
visualize_pipeline(p2)
