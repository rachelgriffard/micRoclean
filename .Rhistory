pipeline2 = function(counts, meta, blocklist, technical_replicates, remove_if = 1,
step2_threshold = 0.5, seed = 42) {
set.seed(seed)
# Step 0: W2W check
#  w2w = well2well(counts, meta, seed = seed)
# Step 1: Remove features that showed different abundance in different batches
## ancombc comparison across batches
s1_res = step1(counts, meta)
# Step 2: Remove features that are differentially abundant in negative controls
## decontam
s2_res = step2(counts, meta, step2_threshold)
# Step 3: Remove if DA in diff batches for technical replicates
s3_res = step3(counts, technical_replicates)
# Step 4: Remove known 'blocklist' of contaminants
s4_res = step4(counts, blocklist)
# Create dataframe indicating TRUE if contaminant and FALSE if not tagged
res = data.frame('feature' = colnames(counts))
res = data.frame('feature' = colnames(counts),
'step1' = ifelse(colnames(counts) %in% s1_res, TRUE, FALSE),
'step2' = ifelse(colnames(counts) %in% s2_res, TRUE, FALSE),
'step3' = ifelse(colnames(counts) %in% s3_res, TRUE, FALSE),
'step4' = ifelse(colnames(counts) %in% s4_res, TRUE, FALSE))
# return column with summed cases where feature was true
# transpose to same as counts matrix
res2 = res
res2$remove = rowSums(res2[,-c(1)])
res2 = t(res2)
# remove features above specified threshold from original counts frame
counts_rem = rbind(counts, res2['remove',])
rownames(counts_rem)[nrow(counts_rem)] = 'remove'
final_counts = counts[,counts_rem['remove',]<remove_if]
removed = setdiff(colnames(counts), colnames(final_counts))
# determine filtering loss value
FL = FL(counts, removed)
# Create deliverable
deliv = list('contaminant_id' = res,
'decontaminated_count' = final_counts,
'removed' = removed,
'filtering_loss' = FL,
'pipeline' = 'pipeline2')
return(deliv)
}
step1 = function(counts, meta) {
phyloseq = wrap_phyloseq(counts, meta)
# run differential analysis
suppressWarnings({
s1 = ANCOMBC::ancombc(phyloseq = phyloseq, assay_name = "counts",  # use package ANCOMBC
group = "batch", p_adj_method = "BH", lib_cut = 0,
formula = "batch",
struc_zero = TRUE, neg_lb = FALSE,
tol = 1e-5, max_iter = 100, conserve = FALSE,
alpha = 0.05, global = TRUE)
})
# create results matrix
s1_res = do.call(cbind, s1$res)
# identify column for diff results
col = ncol(s1_res)
# return indices for which differentially abundant across batches
ind = which(s1_res[,col]==TRUE)
# return list of tagged contaminant features
return(s1_res[ind,1])
}
step2 = function(counts, meta, threshold) {
# subset to only batches that contain negative controls
# create phyloseq object
phyloseq =  wrap_phyloseq(counts, meta)
# run decontam prevalence method
s2_res = decontam::isContaminant(phyloseq, method="prevalence", neg="is_control", threshold=threshold)
# return indices for which features identified as contaminant by decontam prevalence method
ind = which(s2_res$contaminant)
# return list of tagged contaminant features
return(rownames(s2_res[ind,]))
}
step3 = function(counts, technical_replicates) {
# wrap dataframe for technical replicates in each batch ordered by match (line ~336 original_pipeline2.R)
count_replicate = list()
PA_replicate = list()
for (i in 1:dplyr::n_distinct(meta$batch)) {
vals = technical_replicates[,i]
count_replicate[[i]] = data.frame(t(counts[vals,]))
# create presence absence matrices
j = as.matrix(count_replicate[[i]])
j[j!=0] = 1
PA_replicate[[i]] = j
}
# create dataframe to contain results from IRR kappa
kappa_results = data.frame(value = numeric(), statistic = numeric(), p.value = numeric())
# get kappa values using for loop
batch1.df.PA = PA_replicate[[1]]
batch2.df.PA = PA_replicate[[2]]
for (i in nrow(PA_replicate[[1]])) {
k = irr::kappa2(t(rbind(batch1.df.PA[i,], batch2.df.PA[i,])), "unweighted")
kappa_results[i,"value"] = k$value
kappa_results[i,"statistic"] = k$statistic
kappa_results[i,"p.value"] = k$p.value
}
row.names(kappa_results) = colnames(counts)
kappa_results.no_NA = subset(kappa_results, !is.na(value) & !is.na(p.value))
kappa_res_remove = subset(kappa_results.no_NA, p.value >= 0.05 | value <= 0.4)
return(rownames(kappa_res_remove))
}
step4 = function(counts, blocklist) {
allTaxa = colnames(counts)
if (class(blocklist)!='character') {
warning('blocklist input must be formatted as a character vector')
break
}
return(allTaxa[(allTaxa %in% blocklist)])
}
seed = 42
remove(pipeline2)
remove(step1)
remove(step2)
remove(step3)
remove(step4)
### dummy data for development
dat = read.csv("Level6_Genus.csv", header=T,row.name=1)
setwd("~/GitHub/micRoclean_development")
setwd("~/GitHub/micRoclean_development")
### dummy data for development
dat = read.csv("Level6_Genus.csv", header=T,row.name=1)
batch = dat$Batch
group = dat$Groups
index = grep(".*.g__*", colnames(dat)) # keep if have IDed datus
dat = dat[,index]
comp = data.frame(colnames(dat))
comp$compare = sub(".*.g__", "", colnames(dat)) # subset to only datus
index2 = which(comp$compare=="")
comp = comp[-index2,]
index = grep(".*.g__*", colnames(dat)) # keep if have IDed datus
dat = dat[,index]
colnames(dat) = sub(".*.g__", "", colnames(dat)) # subset to only datus
index2 = which(names(dat)=="")
dat = dat[,-index2] # remove if no value
## dummy res data for pipeline2
res = read.csv('res_toydata.csv')
remove(res)
control = group
control = control == "Negative Control"
sample = group
sample[!sample == "Negative Control"] = "Plasma"
sample[sample == "Negative Control"] = "Control"
dat = as.matrix(dat)
meta = data.frame("is_control" = control,
"sample_type" = sample,
"batch" = batch)
rownames(meta) = rownames(dat)
### dummy technical replicates (p2s3)
technical_replicates = data.frame("Batch1" = c("Old_trimmed_2", "Old_trimmed_86",
"Old_trimmed_85", "Old_trimmed_49",
"Old_trimmed_38", "Old_trimmed_3",
"Old_trimmed_13", "Old_trimmed_26"),
"Batch2" = c("New_trimmed_29", "New_trimmed_35",
"New_trimmed_41", "New_trimmed_47",
"New_trimmed_53", "New_trimmed_59",
"New_trimmed_65", "New_trimmed_71"))
# plate wells
well = data.frame()
for (i in 1:8) { # rows
row = c('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H')
for (j in 1:12) { # columns
well[i,j] = paste0(row[i], j, sep = '')
}
}
View(well)
# string for well assignments
vert = unname(unlist(well))
horiz = unname(unlist(data.frame(t(well))))
# order samples by name convention
meta = meta %>%
arrange(batch, as.numeric(str_extract(rownames(meta), "\\d+$")))
library(tidyvers)
library(tidyverse)
# order samples by name convention
meta = meta %>%
arrange(batch, as.numeric(str_extract(rownames(meta), "\\d+$")))
# order batches based on naming convention (number in the end of the string)
meta[order(as.numeric(sub(".*[^0-9](\\d+)$", "\\1", rownames(meta)))),]
# restart at each batch (different plates)
num_b = table(meta$batch)
sample_well = c(vert[1:num_b[1]], vert[1:num_b[2]])
meta_vert = cbind(meta, sample_well)
meta_vert = subset(meta_vert, select = c(is_control, sample_type, sample_well))
sample_well = c(horiz[1:num_b[1]], horiz[1:num_b[2]])
meta_horiz = cbind(meta, sample_well)
meta_horiz = subset(meta_horiz, select = c(is_control, sample_type, sample_well))
# order counts by name convention for SCRuB function
counts = as.data.frame(counts) %>%
add_column(meta$batch) %>%
arrange(`meta$batch`, as.numeric(str_extract(rownames(counts), "\\d+$"))) %>%
mutate(`meta$batch` = NULL)
counts = dat
# order counts by name convention for SCRuB function
counts = as.data.frame(counts) %>%
add_column(meta$batch) %>%
arrange(`meta$batch`, as.numeric(str_extract(rownames(counts), "\\d+$"))) %>%
mutate(`meta$batch` = NULL)
SCRuB_vert = SCRuB(counts,
meta_vert)
# create SCRuB objects
SCRuB_vert = SCRuB::SCRuB(counts,
meta_vert)
