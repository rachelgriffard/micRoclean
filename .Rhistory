hist = mod %>% fit(train_dat, epochs = 10, validation_data = valid_dat)
plot(hist) + theme_minimal() + ggtitle('Model 1')
tensorflow::set_random_seed(42)
# i1 from previous section
o1 = i1 %>%
layer_conv_2d(padding = 'valid',
filters = 64,
kernel_size = c(4,4),
activation = 'relu') %>%
layer_max_pooling_2d(pool_size = c(2,2), strides = 2) %>%
layer_flatten() %>%
layer_dense(units = 32, activation = 'relu') %>%
layer_dense(units = 2, activation = 'softmax')
mod3 = keras_model(inputs = i1, outputs = o1)
mod3 %>% compile(
optimizer = 'adam',
loss = 'sparse_categorical_crossentropy',
metrics = 'accuracy'
)
hist3 = mod3 %>% fit(train_dat, epochs = 10, validation_data = valid_dat)
plot(hist3) + theme_minimal() + ggtitle('Model 3')
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(keras)
library(reticulate)
use_python('C:/Users/rache/anaconda3/envs/tensorflow/python.exe', required=TRUE)
tensorflow::set_random_seed(42)
outcome = c('deer', 'horses')
output_n = length(outcome)
path = 'C:/Users/rache/OneDrive/Desktop/HDSC 882/Final/FinalImages/FinalImages'
image_path = file.path(path, 'train')
train_dat = image_dataset_from_directory(
image_path,
validation_split = 0.2,
subset = "training",
seed = 42,
image_size = c(32, 32)
)
valid_dat = image_dataset_from_directory(
image_path,
validation_split = 0.2,
subset = "validation",
seed = 42,
image_size = c(32, 32)
)
tensorflow::set_random_seed(42)
# i1 from previous section
o1 = i1 %>%
layer_conv_2d(padding = 'valid',
filters = 64,
kernel_size = c(4,4),
activation = 'relu') %>%
layer_max_pooling_2d(pool_size = c(2,2), strides = 2) %>%
layer_flatten() %>%
layer_dense(units = 32, activation = 'tanh') %>%
layer_dense(units = 2, activation = 'softmax')
i1 = layer_input(c(32,32,3))
tensorflow::set_random_seed(42)
# i1 from previous section
o1 = i1 %>%
layer_conv_2d(padding = 'valid',
filters = 64,
kernel_size = c(4,4),
activation = 'relu') %>%
layer_max_pooling_2d(pool_size = c(2,2), strides = 2) %>%
layer_flatten() %>%
layer_dense(units = 32, activation = 'tanh') %>%
layer_dense(units = 2, activation = 'softmax')
mod3 = keras_model(inputs = i1, outputs = o1)
mod3 %>% compile(
optimizer = 'adam',
loss = 'sparse_categorical_crossentropy',
metrics = 'accuracy'
)
hist3 = mod3 %>% fit(train_dat, epochs = 10, validation_data = valid_dat)
plot(hist3) + theme_minimal() + ggtitle('Model 3')
remove(o1)
remove(mod3)
remove(hist3)
o1 = i1 %>%
layer_conv_2d(padding = 'valid',
filters = 64,
kernel_size = c(4,4),
activation = 'relu') %>%
layer_max_pooling_2d(pool_size = c(2,2), strides = 2) %>%
layer_flatten() %>%
layer_dense(units = 32, activation = 'relu') %>%
layer_dense(units = 2, activation = 'softmax')
mod3 = keras_model(inputs = i1, outputs = o1)
mod3 %>% compile(
optimizer = 'adam',
loss = 'sparse_categorical_crossentropy',
metrics = 'accuracy'
)
hist3 = mod3 %>% fit(train_dat, epochs = 10, validation_data = valid_dat)
plot(hist3) + theme_minimal() + ggtitle('Model 3')
plot(hist3) + theme_minimal() + ggtitle('Model 3')
library(tidyverse)
# data
blocklist = read.csv("contaminant-blocklist.csv", header = F)
setwd("C:/Users/rache/OneDrive/Desktop/GRA/Pipelines/MB_Decontamination")
# data
blocklist = read.csv("contaminant-blocklist.csv", header = F)
gen = read.csv("Level6_Genus.csv", header=T,row.name=1)
batch = gen$Batch
group = gen$Groups
age = gen$Age
race = gen$Race
gen = gen[,1:(ncol(gen)-5)] # remove non-count cols
index = grep(".*.g__*", colnames(gen)) # keep if have IDed genus
gen = gen[,index]
comp = data.frame(colnames(gen))
comp$compare = sub(".*.g__", "", colnames(gen)) # subset to only genus
index2 = which(comp$compare=="")
comp = comp[-index2,]
index = grep(".*.g__*", colnames(gen)) # keep if have IDed genus
gen = gen[,index]
colnames(gen) = sub(".*.g__", "", colnames(gen)) # subset to only genus
index2 = which(names(gen)=="")
gen = gen[,-index2] # remove if no value
dat = gen
remove(age)
remove(c(batch,group))
remove(batch)
remove(group)
remove(index)
remove(index2)
remove(race)
remove(blocklist)
remove(comp)
remove(gen)
FL <- function(X){
#X - data matrix
#Ind - only jth taxon removed to calculate FL
p <- dim(X)[2]#total #of taxa
Norm_Ratio <- rep(1, p)
# Check the format of X
if(!(class(X) %in% c("matrix"))){X <- as.matrix(X)}
#Order columns by importance
Order.vec <- NP_Order(X)
X <- X[,Order.vec] #properly order columns of X
Order_Ind <- seq_len(length(Order.vec))
Netw <- t(X)%*%X
#Taxa at the top of the list have smallest number of connected nodes
for (i in seq_len(p)){
Ind <- Order_Ind[-i]
#define matrix X_{-J}'X_{-J} for individual filtering loss
Netw_R <- Netw[Ind, Ind]
Norm_Ratio[i] <-  sum(Netw_R*Netw_R)
}
FL <- 1 - Norm_Ratio/sum(Netw*Netw)
names(FL) <-  colnames(X)
return(data.frame(FL = FL))
}
datfl = FL(dat)
NP_Order <- function(Counts){
#arrange counts in order of increasing number of samples taxa are present in
NP <- names(sort(apply(Counts, 2, Matrix::nnzero)))
return(NP)
}
datfl = FL(dat)
View(datfl)
sum(FL)
sum(datfl$FL)
### dummy data for development
counts = dat # from pipeline.R
res = read.csv('res_toydata.csv')
res = data.frame('step1' = s1_res,
'step2' = s2_res,
'step3' = s3_res,
'step4' = s4_res)
# return column with summed cases where feature was true
res$remove = rowSums(res)
View(res)
class(res$s1_res)
res$s1_res = as.numeric(res$s1_res)
res$s2_res = as.numeric(res$s2_res)
res$s3_res = as.numeric(res$s3_res)
res$s4_res = as.numeric(res$s4_res)
rowSums(res)
View(res)
res = column_to_rownames(res$X)
clsas(res)
class(res)
res = column_to_rownames(res[1])
rlang::last_trace()
rlang::last_trace(drop = FALSE)
rownammes(res) = res[,1]
rownames(res) = res[,1]
res = res[,-1]
View(res)
# return column with summed cases where feature was true
res$remove = rowSums(res)
# transpose to same as counts matrix
res = t(res)
View(res)
# remove features above specified threshold from original counts frame
counts = rbind(counts, res['remove',])
counts = counts['remove' > remove_if,]==TRUE
remove_if = 1
counts = counts['remove' > remove_if,]==TRUE
View(counts)
View(counts)
### dummy data for development
counts = dat # from pipeline.R
counts = counts['remove' > remove_if==TRUE,]
counts = counts[('remove' > remove_if)==TRUE,]
View(counts)
# return column with summed cases where feature was true
res$remove = rowSums(res)
res = read.csv('res_toydata.csv')
res = res[,-1]
rownames(res) = colnames(counts)
# return column with summed cases where feature was true
res$remove = rowSums(res)
# transpose to same as counts matrix
res = t(res)
# remove features above specified threshold from original counts frame
counts = rbind(counts, res['remove',])
counts = counts[('remove' > remove_if)==TRUE,]
View(counts)
counts['remove']
counts['remove',]
res$remove
res = read.csv('res_toydata.csv')
res = res[,-1]
rownames(res) = colnames(counts)
# return column with summed cases where feature was true
res$remove = rowSums(res)
res$remove
View(res)
rowSums(res[1,])
rowSums(res[1,1:4])
rowSums(res[2,1:4])
rowSums(res[3,1:4])
res = read.csv('res_toydata.csv')
View(res)
res = res[,-c(1,5)]
res = read.csv('res_toydata.csv')
res = res[,-c(1,6)]
rownames(res) = colnames(counts)
# return column with summed cases where feature was true
res$remove = rowSums(res)
# transpose to same as counts matrix
res = t(res)
# remove features above specified threshold from original counts frame
counts = rbind(counts, res['remove',])
counts = counts[('remove' > remove_if)==TRUE,]
### dummy data for development
counts = dat # from pipeline.R
# remove features above specified threshold from original counts frame
counts = rbind(counts, res['remove',])
counts[('remove' > remove_if)==TRUE,]
counts['remove'>remove_if]
counts['remove']>remove_if
counts['remove',]>remove_if
class(counts['remove',])
class(counts['remove'])
counts['remove',]
res['remove']
View(res)
res['remove',]
rbind(counts, res['remove',])
counts = rbind(counts, res['remove',])
counts['remove',]
View(counts)
counts[194,]
counts[194,1]
rownames(counts)
# remove features above specified threshold from original counts frame
counts = rbind(counts, res['remove',])
rownames(counts[nrow(counts),]) = 'remove'
rownames(counts[nrow(counts),])
rownames(counts[nrow(counts),])
rownames(counts[nrow(counts),]) = 'remove'
rownames(counts[nrow(counts),])
rownames(counts[nrow(counts),])
rownames(counts[nrow(counts),]) = 'remove'
rownames(counts[195,])
rownames(counts)[nrow(counts),] = 'remove'
rownames(counts)[nrow(counts)] = 'remove'
rownames(counts[195,])
### dummy data for development
counts = dat # from pipeline.R
# remove features above specified threshold from original counts frame
counts = rbind(counts, res['remove',])
rownames(counts)[nrow(counts)] = 'remove'
counts = counts[('remove' > remove_if)==TRUE,]
counts['remove',]
'remove' > remove_if
counts = counts['remove'>remove_if]
counts['remove'>remove_if]
counts['remove'>remove_if,]
counts['remove'>remove_if,]
counts['remove'>remove_if,]==TRUE
counts = counts[counts['remove'>remove_if,]==TRUE,]
sum(res$remove>1)
res = t(res)
sum(res$remove>1)
class(res)
res = data.frame(res)
sum(res$remove>1)
counts = counts[counts['remove'<remove_if,]==TRUE,]
counts = counts[counts['remove'>remove_if,]==TRUE,]
### dummy data for development
counts = dat # from pipeline.R
# remove features above specified threshold from original counts frame
counts = rbind(counts, res['remove',])
rownames(counts)[nrow(counts)] = 'remove'
# transpose to same as counts matrix
res = t(res)
# remove features above specified threshold from original counts frame
counts = rbind(counts, res['remove',])
rownames(counts)[nrow(counts)] = 'remove'
### dummy data for development
counts = dat # from pipeline.R
# remove features above specified threshold from original counts frame
counts = rbind(counts, res['remove',])
rownames(counts)[nrow(counts)] = 'remove'
counts = counts[counts['remove'<remove_if,]==TRUE,]
FL = FL(counts)
View(FL)
FL = FL(dat)
FL = function(X, removed){
#X - data matrix
#Ind - only jth taxon removed to calculate FL
p = dim(X)[2]#total #of taxa
Norm_Ratio = rep(1, p)
# Check the format of X
if(!(class(X) %in% c("matrix"))){X = as.matrix(X)}
#Order columns by importance
Order.vec = NP_Order(X)
X = X[,Order.vec] #properly order columns of X
Order_Ind = seq_len(length(Order.vec))
Netw = t(X)%*%X
#Taxa at the top of the list have smallest number of connected nodes
for (i in seq_len(p)){
Ind = Order_Ind[-i]
#define matrix X_{-J}'X_{-J} for individual filtering loss
Netw_R = Netw[Ind, Ind]
Norm_Ratio[i] =  sum(Netw_R*Netw_R)
}
FL = 1 - Norm_Ratio/sum(Netw*Netw)
names(FL) =  colnames(X)
# FL_value = FL %>%
#   group_by()
#
# return(FL_value)
return(FL = data.frame(FL))
}
FL = FL(dat)
View(FL)
removed = sample(rownames(FL), 100)
FL[rownames(FL) %in% removed,]
sum(FL[rownames(FL) %in% removed,])
FL = function(X, removed){
#X - data matrix
#Ind - only jth taxon removed to calculate FL
p = dim(X)[2]#total #of taxa
Norm_Ratio = rep(1, p)
# Check the format of X
if(!(class(X) %in% c("matrix"))){X = as.matrix(X)}
#Order columns by importance
Order.vec = NP_Order(X)
X = X[,Order.vec] #properly order columns of X
Order_Ind = seq_len(length(Order.vec))
Netw = t(X)%*%X
#Taxa at the top of the list have smallest number of connected nodes
for (i in seq_len(p)){
Ind = Order_Ind[-i]
#define matrix X_{-J}'X_{-J} for individual filtering loss
Netw_R = Netw[Ind, Ind]
Norm_Ratio[i] =  sum(Netw_R*Netw_R)
}
FL = 1 - Norm_Ratio/sum(Netw*Netw)
names(FL) =  colnames(X)
FL_value = sum(FL[rownames(FL) %in% removed,])
return(FL_value)
# return(FL = data.frame(FL))
}
res = data.frame('step1' = s1_res,
'step2' = s2_res,
'step3' = s3_res,
'step4' = s4_res)
source("C:/Users/rache/OneDrive/Desktop/GRA/Pipelines/MB_Decontamination/functions_draft1.R")
library(tidyverse)
install.package('tidyverse')
install.packages('tidyverse')
library(tidyverse)
# data
blocklist = read.csv("contaminant-blocklist.csv", header = F)
gen = read.csv("Level6_Genus.csv", header=T,row.name=1)
batch = gen$Batch
group = gen$Groups
age = gen$Age
race = gen$Race
gen = gen[,1:(ncol(gen)-5)] # remove non-count cols
index = grep(".*.g__*", colnames(gen)) # keep if have IDed genus
gen = gen[,index]
comp = data.frame(colnames(gen))
comp$compare = sub(".*.g__", "", colnames(gen)) # subset to only genus
index2 = which(comp$compare=="")
comp = comp[-index2,]
index = grep(".*.g__*", colnames(gen)) # keep if have IDed genus
gen = gen[,index]
colnames(gen) = sub(".*.g__", "", colnames(gen)) # subset to only genus
index2 = which(names(gen)=="")
gen = gen[,-index2] # remove if no value
dat = gen
remove(blocklist)
remove(comp)
remove(gen)
remove(age)
remove(batch)
remove(group)
remove(index)
remove(index2)
remove(race)
remove(dat)
dat = read.csv("Level6_datus.csv", header=T,row.name=1)
setwd("~/GitHub/micRoclean_development")
dat = read.csv("Level6_datus.csv", header=T,row.name=1)
blocklist = read.csv("contaminant-blocklist.csv", header = F)
gen = read.csv("Level6_Genus.csv", header=T,row.name=1)
batch = gen$Batch
group = gen$Groups
age = gen$Age
race = gen$Race
gen = gen[,1:(ncol(gen)-5)] # remove non-count cols
index = grep(".*.g__*", colnames(gen)) # keep if have IDed genus
gen = gen[,index]
comp = data.frame(colnames(gen))
comp$compare = sub(".*.g__", "", colnames(gen)) # subset to only genus
index2 = which(comp$compare=="")
comp = comp[-index2,]
index = grep(".*.g__*", colnames(gen)) # keep if have IDed genus
gen = gen[,index]
colnames(gen) = sub(".*.g__", "", colnames(gen)) # subset to only genus
index2 = which(names(gen)=="")
gen = gen[,-index2] # remove if no value
dat = gen
install.packages('phyloseq')
install.packages('SummarizedExperiment')
install.packages('plotly')
install.packages('PERfect')
install.packages('decontam')
install.packages('microDecon')
install.packages('ANCOMBC')
install.packages('ggVennDiagram')
install.packages('shiny')
install.packages('DESeq2')
install.packages('edgeR')
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install(version = "3.19")
if (!require("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install(version = "3.18")
BiocManager::install(c("edgeR", "DESeq2"))
BiocManager::install(c("SingleCellExperiment", "Seraut", "ComplexHeatmap", "topGO"))
install.packages(c('MASS', 'psych', 'tree', 'e1071', 'caret', 'tensorflow'))
install.packages('keras')
install.packages('RColorBrewer')
install.packages(c("devtools","usethis","roxygen2","knitr",
"rmarkdown","flexdashboard","Shiny",
"xtable","httr","profvis"), dependencies = TRUE)
library(microDecon)
BiocManager::install('microDecon')
install.packages("devtools") #Installs devtools (if not already installed)
devtools::install_github("donaldtmcknight/microDecon") #Installs microDecon
library(microDecon)
View(dat)
example <- cbind.data.frame(c("OTU1","OTU2","OTU3","OTU4","OTU5","OTU6"),
c(0,200,1000,50,0,25),
c(0,220,800,30,0,10),
c(0,180,1300,70,0,30),
c(60,660,1440,70,2400,30),
c(64,520,1000,48,1900,20),
c(40,480,700,35,2100,15),
c("K_Bacteria; P_Actinobacteria","K_Bacteria; P_Proteobacteria","K_Bacteria; P_Proteobacteria","K_Bacteria; P_Bacteroidetes","K_Bacteria","K_Bacteria"))
colnames(example) <- c("OTU_ID","Blank1","Blank2","Blank3","Pop1_Sample1","Pop1_Sample2","Pop2_Sample3","Taxa")
View(example)
dat2 = t(dat)
View(dat2)
dat2$OTU_ID = paste0('OTU', 1:nrow(dat2))
dat2 = t(dat)
dat2 = data.frame(t(dat))
dat2$OTU_ID = c(paste0('OTU', 1:nrow(dat2)))
View(dat2)
dat2$OTU_ID
dat2$taxa = rownames(dat2)
dat2 = unname(dat2)
dat2 = data.frame(t(dat))
dat2$OTU_ID = c(paste0('OTU', 1:nrow(dat2)))
dat2$taxa = rownames(dat2)
rownames(dat2) = NULL
decontaminated = decon(dat, numb.blanks = 6, numb.ind = c(1,4,6,3,7,9), taxa = T)
dat2 %>%
relocate(OTU_ID, .before = New_trimmed_1)
decontaminated = decon(dat, numb.blanks = 6, numb.ind = c(1,4,6,3,7,9), taxa = T)
dat2 = dat2 %>%
relocate(OTU_ID, .before = New_trimmed_1)
decontaminated = decon(dat, numb.blanks = 6, numb.ind = c(1,4,6,3,7,9), taxa = T)
decontaminated = decon(dat2, numb.blanks = 6, numb.ind = c(1,4,6,3,7,9), taxa = T)
decontaminated = decon(dat2, numb.blanks = 6, numb.ind = c(21,4,6,3,7,9), taxa = T)
194/2
decontaminated = decon(dat2, numb.blanks = 6, numb.ind = c(97, 97), taxa = T)
decontaminated = decon(dat2, numb.blanks = 6, numb.ind = c(96, 96), taxa = T)
ncol(dat2)
(ncol(dat2)-2)/2
decontaminated = decon(dat2, numb.blanks = 6, numb.ind = c(90, 96), taxa = T)
View(decontaminated)
