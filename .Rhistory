dat = read.csv("Level6_Genus.csv", header=T,row.name=1)
setwd("~/GitHub/micRoclean_development")
dat = read.csv("Level6_Genus.csv", header=T,row.name=1)
batch = dat$Batch
group = dat$Groups
index = grep(".*.g__*", colnames(dat)) # keep if have IDed datus
dat = dat[,index]
comp = data.frame(colnames(dat))
comp$compare = sub(".*.g__", "", colnames(dat)) # subset to only datus
index2 = which(comp$compare=="")
comp = comp[-index2,]
index = grep(".*.g__*", colnames(dat)) # keep if have IDed datus
dat = dat[,index]
colnames(dat) = sub(".*.g__", "", colnames(dat)) # subset to only datus
index2 = which(names(dat)=="")
dat = dat[,-index2] # remove if no value
control = group
control = control == "Negative Control"
sample = group
sample[!sample == "Control"] = "Plasma"
dat = as.matrix(dat)
meta = data.frame("is_control" = control,
"sample" = sample,
"batch" = batch)
rownames(meta) = rownames(dat)
### dummy technical replicates (p2s3)
technical_replicates = data.frame("Batch1" = c("Old_trimmed_2", "Old_trimmed_86",
"Old_trimmed_85", "Old_trimmed_49",
"Old_trimmed_38", "Old_trimmed_3",
"Old_trimmed_13", "Old_trimmed_26"),
"Batch2" = c("New_trimmed_29", "New_trimmed_35",
"New_trimmed_41", "New_trimmed_47",
"New_trimmed_53", "New_trimmed_59",
"New_trimmed_65", "New_trimmed_71"))
remove(comp)
remove(batch)
remove(control)
remove(group)
remove(index)
remove(index2)
remove(sample)
counts = dat
# wrap dataframe for technical replicates in each batch ordered by match (line ~336 original_pipeline2.R)
count_replicate = list()
PA_replicate = list()
i = 1
vals = technical_replicates[,i]
count_replicate[[i]] = data.frame(t(counts[vals,]))
# create presence absence matrices
k = count_replicate[[i]]
k = k %>%
mutate(ifelse(k>0, 1, 0))
# Required libraries
library(phyloseq) # object wrapper
library(SummarizedExperiment) # object wrapper
library(tidyverse)
library(plotly) # for interactive feature
library(SCRuB) # pipeline 1
library(decontam) # pipeline 2 step2
library(microDecon) # pipeline 2
library(ANCOMBC) # pipeline 2
library(ggVennDiagram) # function 3 - pipeline 2 - comparison across removed
library(shiny) # function 3
library(ANCOMBC) # pipeline 2 step1
library(irr) # pipeline 2 step3
wrap_phyloseq = function(counts, meta) {
counts = t(counts) # transpose to fit with expectation of phyloseq object
OTU = otu_table(counts, taxa_are_rows = TRUE)
META = sample_data(meta)
tax_mat = matrix(rownames(counts),nrow=nrow(counts),ncol=1)
rownames(tax_mat) = rownames(counts)
TAX = tax_table(tax_mat)
return(phyloseq(OTU, META, TAX))
}
k = k %>%
mutate(ifelse(k>0, 1, 0))
PA_replicate[[i]] = k
View(PA_replicate)
k = k %>%
mutate(ifelse(k==0, 0, 1))
# create presence absence matrices
k = count_replicate[[i]]
k[[i]] = k[[i]] %>%
mutate(ifelse(k[[i]]>0, 1, 0))
# create presence absence matrices
k = count_replicate[[i]]
k[[i]] = k[[i]] %>%
mutate(k[[i]]!=0)
k[[i]] = k %>%
mutate(k[[i]]!=0)
PA_replicate[[i]] = k
View(PA_replicate)
k = k %>%
mutate(k!=0)
View(k)
k!=0
k = k %>%
mutate(lapply(ifelse(k>0, 1, 0)))
k = k %>%
mutate(lapply(ifelse(k>0, 1, 0), k))
k = k %>%
mutate(mapply(ifelse(k>0, 1, 0), k))
lapply(ifelse(k>0, 1, 0), k)
ifelse(k>0, 1, 0)
k>0
k>=0
class(k)
k != 0
k == 0
k[k!=0] = 1
# create presence absence matrices
k = matrix(count_replicate[[i]])
# create presence absence matrices
k = as.matrix(count_replicate[[i]])
k[k!=0] = 1
PA_replicate[[i]] = k
for (i in 1:dplyr::n_distinct(meta$batch)) {
vals = technical_replicates[,i]
count_replicate[[i]] = data.frame(t(counts[vals,]))
# create presence absence matrices
k = as.matrix(count_replicate[[i]])
k[k!=0] = 1
PA_replicate[[i]] = k
}
# create dataframe to contain results from IRR kappa
kappa_results = data.frame(value = numeric(), statistic = numeric(), p.value = numeric())
for (i in nrow(batch_1)) {
batch1.df.PA = PA_replicate[[1]]
batch2.df.PA = PA_replicate[[2]]
k = kappa2(t(rbind(batch1.df.PA[i,], batch2.df.PA[i,])), "unweighted")
kappa_results[i,"value"] = k$value
kappa_results[i,"statistic"] = k$statistic
kappa_results[i,"p.value"] = k$p.value
}
# get kappa values using for loop
for (i in nrow(PA_replicate[[1]])) {
batch1.df.PA = PA_replicate[[1]]
batch2.df.PA = PA_replicate[[2]]
k = kappa2(t(rbind(batch1.df.PA[i,], batch2.df.PA[i,])), "unweighted")
kappa_results[i,"value"] = k$value
kappa_results[i,"statistic"] = k$statistic
kappa_results[i,"p.value"] = k$p.value
}
row.names(kappa_results) = taxa_names(genus_new.df.PA)
View(batch1.df.PA)
row.names(kappa_results) = colnames(counts)
View(kappa_results)
i = 1
batch1.df.PA = PA_replicate[[1]]
batch2.df.PA = PA_replicate[[2]]
k = kappa2(t(rbind(batch1.df.PA[i,], batch2.df.PA[i,])), "unweighted")
View(k)
t(rbind(batch1.df.PA[i,], batch2.df.PA[i,]))
rbind(batch1.df.PA[i,], batch2.df.PA[i,])
kappa2((rbind(batch1.df.PA[i,], batch2.df.PA[i,])), "unweighted")
kappa2(t(rbind(batch1.df.PA[i,], batch2.df.PA[i,])), "unweighted")
i =15
class(PA_replicate[[i]])
batch1.df.PA
View(batch1.df.PA)
batch1.df.PA$Old_trimmed_2
i = 1
kappa_results[i,"value"]
i = 1
batch1.df.PA = PA_replicate[[1]]
batch2.df.PA = PA_replicate[[2]]
k = kappa2(t(rbind(batch1.df.PA[i,], batch2.df.PA[i,])), "unweighted")
View(k)
rbind(batch1.df.PA[i,], batch2.df.PA[i,]
)
temp = rbind(batch1.df.PA[i,], batch2.df.PA[i,])
View(temp)
temp = rbind(batch1.df.PA[,i], batch2.df.PA[,i])
k = kappa2(rbind(batch1.df.PA[,i], batch2.df.PA[,i])), "unweighted")
k = kappa2(rbind(batch1.df.PA[,i], batch2.df.PA[,i]), "unweighted")
k = kappa2(t(rbind(batch1.df.PA[,i], batch2.df.PA[,i])), "unweighted")
View(k)
# get kappa values using for loop
for (i in nrow(PA_replicate[[1]])) {
batch1.df.PA = PA_replicate[[1]]
batch2.df.PA = PA_replicate[[2]]
k = kappa2(t(rbind(batch1.df.PA[,i], batch2.df.PA[,i])), "unweighted")
kappa_results[i,"value"] = k$value
kappa_results[i,"statistic"] = k$statistic
kappa_results[i,"p.value"] = k$p.value
}
batch1.df.PA = PA_replicate[[1]]
batch2.df.PA = PA_replicate[[2]]
k = kappa2(t(rbind(batch1.df.PA[,i], batch2.df.PA[,i])), "unweighted")
i = 1
# get kappa values using for loop
for (i in ncol(PA_replicate[[1]])) {
batch1.df.PA = PA_replicate[[1]]
batch2.df.PA = PA_replicate[[2]]
k = kappa2(t(rbind(batch1.df.PA[,i], batch2.df.PA[,i])), "unweighted")
kappa_results[i,"value"] = k$value
kappa_results[i,"statistic"] = k$statistic
kappa_results[i,"p.value"] = k$p.value
}
row.names(kappa_results) = colnames(counts)
View(kappa_results)
# get kappa values using for loop
for (i in ncol(PA_replicate[[1]])) {
batch1.df.PA = PA_replicate[[1]]
batch2.df.PA = PA_replicate[[2]]
k = kappa2(t(rbind(batch1.df.PA[,i], batch2.df.PA[,i])), "unweighted")
kappa_results[i,"value"] = k$value
kappa_results[i,"statistic"] = k$statistic
kappa_results[i,"p.value"] = k$p.value
}
# Create genus phyloseq object with all meta data
d.genus = cbind(batch, group, age, race, group, gen) # remove non MB, move groups to front
gen = read.csv("../Data/Level6_Genus.csv", header=T,row.name=1)
setwd("~/GitHub/micRoclean_development")
gen = read.csv("../Data/Level6_Genus.csv", header=T,row.name=1)
gen = read.csv("Level6_Genus.csv", header=T,row.name=1)
# Extract meta data
batch = gen$Batch
group = gen$Groups
age = gen$Age
race = gen$Race
gen = gen[,1:(ncol(gen)-5)] # remove non-count cols
index = grep(".*.g__*", colnames(gen)) # keep if have IDed genus
gen = gen[,index]
comp = data.frame(colnames(gen))
comp$compare = sub(".*.g__", "", colnames(gen)) # subset to only genus
index2 = which(comp$compare=="")
comp = comp[-index2,]
# Adjust names to genus alone
index = grep(".*.g__*", colnames(gen)) # keep if have IDed genus
gen = gen[,index]
colnames(gen) = sub(".*.g__", "", colnames(gen)) # subset to only genus
index2 = which(names(gen)=="")
gen = gen[,-index2] # remove if no value
## removes 650 based on lack of genus alone
# Create genus phyloseq object with all meta data
d.genus = cbind(batch, group, age, race, group, gen) # remove non MB, move groups to front
colnames(d.genus)[1] = "Batch"
d.genus$Batch[d.genus$Batch=="Old"] = "1. Old" # to set old as reference
d.genus$Batch[d.genus$Batch=="New"] = "2. New"
table(d.genus$Batch)
colnames(d.genus)[2] = "Groups"
d.genus$Groups[d.genus$Groups=="Negative Control"] = "0.Negative Control"
d.genus$Groups[d.genus$Groups=="Control"] = "1.Control"
d.genus$Groups[d.genus$Groups=="Benign"] = "2.Sample"
d.genus$Groups[d.genus$Groups=="Non_EOC"] = "2.Sample"
d.genus$Groups[d.genus$Groups=="EOC"] = "2.Sample"
table(d.genus$Groups)
colnames(d.genus)[3] = "Age"
table(d.genus$Age)
colnames(d.genus)[4] = "Race"
table(d.genus$Race)
colnames(d.genus)[5] = "Ex_Groups"
d.genus$Groups[d.genus$Groups=="Negative Control"] = "0.Negative Control"
d.genus$Groups[d.genus$Groups=="Control"] = "1.Control"
d.genus$Groups[d.genus$Groups=="Benign"] = "2.Sample"
d.genus$Groups[d.genus$Groups=="Non_EOC"] = "3.Sample"
d.genus$Groups[d.genus$Groups=="EOC"] = "4.Sample"
table(d.genus$Groups)
d.genus.ancomBC = t(d.genus[,6:ncol(d.genus)]) # non meta data
d.genus.ancomBC = round(d.genus.ancomBC)
all(colnames(d.genus.ancomBC)==rownames(d.genus))
otu_mat = d.genus.ancomBC
meta = data.frame(group=d.genus$Groups,
batch=d.genus$Batch,
# age=d.genus$Age,
# race=d.genus$Race,
ex_groups=d.genus$Ex_Groups,
row.names=colnames(d.genus.ancomBC))
tax_mat = matrix(rownames(otu_mat),nrow=nrow(otu_mat),ncol=1)
rownames(tax_mat) = rownames(otu_mat)
colnames(tax_mat) = c("genus")
OTU_g = otu_table(otu_mat, taxa_are_rows = TRUE)
META_g = sample_data(meta)
TAX_g = tax_table(tax_mat)
genus = phyloseq(OTU_g, META_g, TAX_g)
rs = technical_replicates
# create dataframes for shared samples
genus_new_sh = prune_samples(rs$Batch1, genus)
genus_old_sh = prune_samples(rs$Batch2, genus)
genus_new.df = otu_table(genus_new_sh) # Extract OTU table from phyloseq object
genus_new.df.PA = transform_sample_counts(genus_new.df, function(abund) 1*(abund>0)) # Set as present/absence
genus_old.df = otu_table(genus_old_sh) # Extract OTU table from phyloseq object
genus_old.df.PA = transform_sample_counts(genus_old.df, function(abund) 1*(abund>0))
View(genus_old.df.PA)
View(batch2.df.PA)
# get kappa values using for loop
batch1.df.PA = PA_replicate[[1]]
batch2.df.PA = PA_replicate[[2]]
for (i in nrow(PA_replicate[[1]])) {
k = kappa2(t(rbind(batch1.df.PA[i,], batch2.df.PA[i,])), "unweighted")
kappa_results[i,"value"] = k$value
kappa_results[i,"statistic"] = k$statistic
kappa_results[i,"p.value"] = k$p.value
}
View(kappa_results)
row.names(kappa_results) = colnames(counts)
kappa_results.no_NA = subset(kappa_results, !is.na(value) & !is.na(p.value))
kappa_results_sig = subset(kappa_results.no_NA, p.value < 0.05)
kappa_res_keep = subset(kappa_results.no_NA, p.value < 0.05 & value > 0.4)
kappa_res_keep = cbind(tax_table(genus)[row.names(kappa_res_keep), "genus"], kappa_res_keep)
View(kappa_results.no_NA)
# calculate kappa-statistic for all ASVs shared btwn DNA extraction batches
kappa_results = data.frame(value = numeric(), statistic = numeric(), p.value = numeric())
for(i in 1:nrow(genus_new.df.PA)){
k = kappa2(t(rbind(genus_new.df.PA[i,], genus_old.df.PA[i,])), "unweighted")
kappa_results[i,"value"] = k$value
kappa_results[i,"statistic"] = k$statistic
kappa_results[i,"p.value"] = k$p.value
}
row.names(kappa_results) = taxa_names(genus_new.df.PA)
kappa_results.no_NA = subset(kappa_results, !is.na(value) & !is.na(p.value))
View(kappa_results.no_NA)
genus_old.df.PA == batch2.df.PA
sum(genus_old.df.PA == batch2.df.PA)
564*8
sum(genus_new.df.PA == batch1.df.PA)
genus_new.df.PA == batch1.df.PA
colnames(batch1.df.PA)
colnames(genus_new.df)
return(rownames(kappa_res_remove))
step3 = function(counts, meta, technical_replicates) {
# wrap dataframe for technical replicates in each batch ordered by match (line ~336 original_pipeline2.R)
count_replicate = list()
PA_replicate = list()
for (i in 1:dplyr::n_distinct(meta$batch)) {
vals = technical_replicates[,i]
count_replicate[[i]] = data.frame(t(counts[vals,]))
# create presence absence matrices
j = as.matrix(count_replicate[[i]])
j[j!=0] = 1
PA_replicate[[i]] = j
}
# create dataframe to contain results from IRR kappa
kappa_results = data.frame(value = numeric(), statistic = numeric(), p.value = numeric())
# get kappa values using for loop
batch1.df.PA = PA_replicate[[1]]
batch2.df.PA = PA_replicate[[2]]
for (i in nrow(PA_replicate[[1]])) {
k = kappa2(t(rbind(batch1.df.PA[i,], batch2.df.PA[i,])), "unweighted")
kappa_results[i,"value"] = k$value
kappa_results[i,"statistic"] = k$statistic
kappa_results[i,"p.value"] = k$p.value
}
row.names(kappa_results) = colnames(counts)
kappa_results.no_NA = subset(kappa_results, !is.na(value) & !is.na(p.value))
kappa_res_remove = subset(kappa_results.no_NA, p.value >= 0.05 | value <= 0.4)
return(rownames(kappa_res_remove))
}
step3(dat, meta, rs)
step3 = function(counts, technical_replicates) {
# wrap dataframe for technical replicates in each batch ordered by match (line ~336 original_pipeline2.R)
count_replicate = list()
PA_replicate = list()
for (i in 1:dplyr::n_distinct(meta$batch)) {
vals = technical_replicates[,i]
count_replicate[[i]] = data.frame(t(counts[vals,]))
# create presence absence matrices
j = as.matrix(count_replicate[[i]])
j[j!=0] = 1
PA_replicate[[i]] = j
}
# create dataframe to contain results from IRR kappa
kappa_results = data.frame(value = numeric(), statistic = numeric(), p.value = numeric())
# get kappa values using for loop
batch1.df.PA = PA_replicate[[1]]
batch2.df.PA = PA_replicate[[2]]
for (i in nrow(PA_replicate[[1]])) {
k = kappa2(t(rbind(batch1.df.PA[i,], batch2.df.PA[i,])), "unweighted")
kappa_results[i,"value"] = k$value
kappa_results[i,"statistic"] = k$statistic
kappa_results[i,"p.value"] = k$p.value
}
row.names(kappa_results) = colnames(counts)
kappa_results.no_NA = subset(kappa_results, !is.na(value) & !is.na(p.value))
kappa_res_remove = subset(kappa_results.no_NA, p.value >= 0.05 | value <= 0.4)
return(rownames(kappa_res_remove))
}
step3(dat, rs)
# wrap dataframe for technical replicates in each batch ordered by match (line ~336 original_pipeline2.R)
count_replicate = list()
PA_replicate = list()
for (i in 1:dplyr::n_distinct(meta$batch)) {
vals = technical_replicates[,i]
count_replicate[[i]] = data.frame(t(counts[vals,]))
# create presence absence matrices
j = as.matrix(count_replicate[[i]])
j[j!=0] = 1
PA_replicate[[i]] = j
}
# create dataframe to contain results from IRR kappa
kappa_results = data.frame(value = numeric(), statistic = numeric(), p.value = numeric())
# get kappa values using for loop
batch1.df.PA = PA_replicate[[1]]
batch2.df.PA = PA_replicate[[2]]
for (i in nrow(PA_replicate[[1]])) {
k = kappa2(t(rbind(batch1.df.PA[i,], batch2.df.PA[i,])), "unweighted")
kappa_results[i,"value"] = k$value
kappa_results[i,"statistic"] = k$statistic
kappa_results[i,"p.value"] = k$p.value
}
row.names(kappa_results) = colnames(counts)
kappa_results.no_NA = subset(kappa_results, !is.na(value) & !is.na(p.value))
kappa_res_remove = subset(kappa_results.no_NA, p.value >= 0.05 | value <= 0.4)
return(rownames(kappa_res_remove))
rownames(kappa_res_remove)
View(kappa_results.no_NA)
for (i in nrow(PA_replicate[[1]])) {
k = kappa2(t(rbind(batch1.df.PA[i,], batch2.df.PA[i,])), "unweighted")
kappa_results[i,"value"] = k$value
kappa_results[i,"statistic"] = k$statistic
kappa_results[i,"p.value"] = k$p.value
}
row.names(kappa_results) = colnames(counts)
View(kappa_results)
